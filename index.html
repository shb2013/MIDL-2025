<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Segmentation‑Informed Captioning – MIDL 2025 Poster</title>

  <!-- ------  Basic, mobile‑first styling  ------ -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <style>
    :root{
      --accent:#ff6600;           
      --max-width: 900px;
      font-family: Arial, Helvetica, sans-serif;
    }
    body{margin:0;padding:0;background:#fafafa;color:#222;line-height:1.55;}
    header{background:var(--accent);color:#fff;padding:1.3rem 0;text-align:center;}
    h1{margin:0;font-size:clamp(1.4rem,4vw,2rem);}
    main{max-width:var(--max-width);margin:auto;padding:1.2rem;}
    section{margin-bottom:2.5rem;}
    section h2{color:var(--accent);margin-bottom:.6rem}

    /* Minimal poster / video wrappers */
    .poster-wrapper, .video-wrapper{
      display:flex; flex-direction:column; align-items:center;
    }
    .poster-wrapper iframe,
    .poster-wrapper img{
      width:100%;max-width:var(--max-width);border:none;
      aspect-ratio: 1 / 1.414;   /* A‑series portrait (≈ 210 × 297 mm) */
    }
    /* shadow so white poster stands out on phones */
    .poster-wrapper img{box-shadow:0 4px 16px rgba(0,0,0,.12);}

    /*  Narrow iFrames need full width */
    .video-wrapper iframe{
      width:100%; aspect-ratio:16/9; border:none;
      box-shadow:0 4px 16px rgba(0,0,0,.12);
    }

    /* Footer */
    footer{font-size:.85rem;text-align:center;padding:1rem 0;background:#eee;color:#666;}
    a{color:var(--accent)}
  </style>
</head>
<body>

<header>
  <h2>MIDL 2025 - Short Paper Submission no. 77</h2>
  <h1>Segmentation‑Informed Captioning: A Multi‑Stage Pipeline for Surgical Vision–Language Dataset Generation</h1>
  <h4>Mohamed Hamdy, Fatmaelzahraa Ali Ahmed, Mariam Ahmed, Mohannad AbuHaweeleh, Muraam Abdel-Ghani, Muhammed Arsalan, Abdulaziz Al-Ali, Shidin Balakrishnan </h4>
</header>

<main>

  <!-- =====  ABSTRACT  ===== -->
  <section id="abstract">
    <h2>Abstract</h2>
    <p>
     
      General surgical understanding aims to develop models that generalize across procedures and tasks, in contrast to fully-supervised, task-specific approaches. Recent work has explored VLMs for this purpose. 
      However, their effectiveness–particularly on tasks requiring fine-grained scene understanding–is often constrained by noisy and misaligned datasets, typically based on transcribed audio. 
      In this paper, we propose a five-stage pipeline to construct more accurate and less noisy vision-language datasets from existing segmentation datasets. 
      Our method applies rule-based heuristics to extract spatial, and interaction cues, which are then used to prompt a large language model (LLM) to produce naturally sound, clinically coherent captions. Evaluation by three medical experts on how well the 
      captions met stage-specific expectation found that 95% of the generated captions scored 3 or higher on a Likert scale.
      
      <br><strong> Keywords:</strong> Vision-Language Models, Surgical Captioning, Surgical Scene Understanding</br>
    </p>
  </section>


  <!-- =====  POSTER  ===== -->
  <section id="poster">
    <h2>Conference Poster</h2>

    <!-- Option A (desktop): inline PDF viewer -->
    <div class="poster-wrapper" style="display:none" id="pdfPoster">
      <iframe
        src="Poster.pdf#zoom=page-fit"
        title="Poster PDF">
      </iframe>
      <p style="font-size:.9rem;opacity:.7">You can zoom or download the PDF using the built‑in toolbar.</p>
    </div>

    <!-- Option B (mobile fallback): static image -->
    <div class="poster-wrapper" id="imgPoster">
      <!-- Replace poster.png with an exported 150 DPI PNG of the PDF -->
      <img src="poster.png" alt="Conference Poster">
    </div>

    <script>
      /* Show PDF on wide screens, image on small ones */
      const pdfDiv = document.getElementById('pdfPoster');
      const imgDiv = document.getElementById('imgPoster');
      function switchPoster(){
        if(window.innerWidth > 768){
          pdfDiv.style.display='block'; imgDiv.style.display='none';
        }else{
          pdfDiv.style.display='none'; imgDiv.style.display='block';
        }
      }
      switchPoster(); window.addEventListener('resize', switchPoster);
    </script>
  </section>


  <!-- =====  VIDEO  ===== -->
  <section id="video">
    <h2>Poster‑Pitch Video</h2>
    <div class="video-wrapper">
      
      <iframe
        src="https://www.youtube.com/embed/jjSKvIwqzkA?si=MDkLMZQZRkkOO6a2"
        title="Poster video"
        allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
        allowfullscreen>
      </iframe>
    </div>
  </section>

</main>

<footer>
  © 2025 Shidin Balakrishnan et al. · Grant&nbsp;ARG01‑0522‑230266
</footer>

</body>
</html>
